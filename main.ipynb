{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ef2dd7",
   "metadata": {},
   "source": [
    "### Transformers-Explainability\n",
    "Follow this pipeline to interpret a model's choice using different XAI methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download raw datasets (can take some time) and import dataset creation functions\n",
    "%run dataset_creator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac71875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create intermediate datasets (can take a while)\n",
    "text_processor = TextProcessor(None)\n",
    "ac = AsyLexCleaner(text_processor=text_processor)\n",
    "ac.create_all_intermediate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose model, paragraph_selection_strategy and dataset\n",
    "model_name = 'bert' #'roberta'\n",
    "dataset_name = 'asylex-outcome' #'asylex-outcome' 'sentiment1' 'sentiment2'\n",
    "paragraph_selection_strategy = 'first' #'rand' 'cas' 'first' 'last' '' #use the last for sentiment1 and sentiment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset\n",
    "text_processor = TextProcessor(None)\n",
    "dh = DatasetHandler(info=None,model=model_name,text_processor=text_processor)\n",
    "dataset_path, model_path, num_labels = dh.import_paths_and_nlabels(dataset_name,model_name,paragraph_selection_strategy)\n",
    "created_dataset = dh.create_dataset(dataset_name,paragraph_selection_strategy,subset_dimension=None)\n",
    "dh.write_dataset(dataset_path,created_dataset)\n",
    "del created_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9b2cd",
   "metadata": {},
   "source": [
    "#### Proceed training the model using train_and_test.ipynb\n",
    "When the training is done and the models are saved in the proper models folder, you can move on to the following stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a51891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XAI classes and functions\n",
    "%run XAI.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4534216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset and model\n",
    "train_set,test_set,validation_set,tokenizer,model = Loader.import_dataset_and_model(dataset_name,model_name,paragraph_selection_strategy)\n",
    "dataset = test_set\n",
    "del test_set\n",
    "del train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0c6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3943, -2.0822]])\n",
      "tensor([[ 2.9225, -2.5276]])\n",
      "tensor([[ 2.8120, -2.4954]])\n",
      "tensor([[ 2.9994, -2.6536]])\n",
      "tensor([[ 2.3034, -1.6276]])\n",
      "tensor([[ 2.0531, -1.6227]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_sentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43mundecided_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mundecided_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmethod_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m ac\u001b[38;5;241m.\u001b[39mcreate_comparison(method_list)\n\u001b[0;32m     20\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19204\\1438807038.py:76\u001b[0m, in \u001b[0;36mAnalysisCreator.create_scores\u001b[1;34m(self, method_list, n_sentences, undecided_threshold)\u001b[0m\n\u001b[0;32m     74\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sentence)\n\u001b[0;32m     75\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mground_truth[count]\n\u001b[1;32m---> 76\u001b[0m visual_explanation \u001b[38;5;241m=\u001b[39m \u001b[43mmy_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp_org\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpred_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(visual_explanation) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokens):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(my_method\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19204\\2306362820.py:43\u001b[0m, in \u001b[0;36mGeneric_xai_method.method_pipeline\u001b[1;34m(self, sentence, embedding, tokens, p_org, pred_class)\u001b[0m\n\u001b[0;32m     41\u001b[0m filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_filters(sentence,embedding)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#probabilities = my_method.filter_prob_masked_attention(filters,sentence,predicted_classes[count])\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters_to_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpred_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m visual_explanation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mlen\u001b[39m(filters),\u001b[38;5;28mlen\u001b[39m(tokens)))\n\u001b[0;32m     45\u001b[0m uniqueness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_uniqueness(probabilities)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19204\\3285647264.py:51\u001b[0m, in \u001b[0;36mrangedCSM.filters_to_probabilities\u001b[1;34m(self, filters, sentence, ground_truth)\u001b[0m\n\u001b[0;32m     49\u001b[0m     masked_embeddings[\u001b[38;5;241m0\u001b[39m,[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m],:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#required that list comprension intead of simply \"filters\" because of sep cls tokens\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(inputs_embeds \u001b[38;5;241m=\u001b[39m masked_embeddings,attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 51\u001b[0m     \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     probabilities\u001b[38;5;241m.\u001b[39mappend(F\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m][ground_truth])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#use XAI methods\n",
    "n_embeddings = 6 #number of embeddings to be generated. this must be >= n_sentences\n",
    "n_sentences = 2\n",
    "undecided_threshold = 0.4\n",
    "\n",
    "my_lime = LIME(['negative','positive'],510,1000,clipped_heatmap=False,analytics=DataAnalysis(method_name='lime',create_plot=True,create_stats=True,relevance_threshold=0.01))\n",
    "my_shap = SHA(clipped_heatmap=False,analytics=DataAnalysis(method_name='shap',create_plot=True,create_stats=True,relevance_threshold=0.1))\n",
    "my_doa = DOA(analytics=DataAnalysis(method_name='diff_of_angle_pho',create_plot=True,create_stats=True,relevance_threshold=4.0))\n",
    "my_rang_csm = rangedCSM(analytics=DataAnalysis(method_name='ranged_csm',create_plot=True,create_stats=True,relevance_threshold=0.35))\n",
    "method_list = [my_rang_csm,my_shap] #this is the list of methods that will be applied\n",
    "\n",
    "ac = AnalysisCreator('try1')\n",
    "_ = model.to('cpu')\n",
    "embeddings_manager.generate_embeddings(dataset_name,model_name,paragraph_selection_strategy,n_embeddings)\n",
    "ac.load_embeddings(n_embeddings)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "ac.create_scores(n_sentences=n_sentences,undecided_threshold=undecided_threshold,method_list=method_list)\n",
    "ac.create_comparison(method_list)\n",
    "_ = model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc94621",
   "metadata": {},
   "source": [
    "see the results in the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8321ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other implemented methods\n",
    "my_lime = LIME(['negative','positive'],510,1000)\n",
    "my_shap = SHA(clipped_heatmap=False,analytics=DataAnalysis(create_plot=True,create_stats=True,relevance_threshold=0.1))\n",
    "my_doa = DOA(analytics=DataAnalysis(create_plot=True,create_stats=True,relevance_threshold=4.0))\n",
    "my_ned = NED()\n",
    "my_csm = CSM()\n",
    "my_new_csm = newCSM()\n",
    "my_cos_sim = cosine_similarity(analytics=DataAnalysis(create_plot=True,create_stats=True,relevance_threshold=0.35)) #analytics=DataAnalysis(create_plot=True,create_stats=True,relevance_threshold=0.35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
